#!/usr/bin/env python3
"""
Test the enhanced console output with thinking process and final results.
This script demonstrates the new detailed output format.
"""

import sys
import os

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_enhanced_output_format():
    """Test that our enhanced output methods work correctly."""
    print("TESTING ENHANCED CONSOLE OUTPUT")
    print("=" * 60)
    
    # Test the message handling classes
    try:
        from Red.message_manager import MessageBuilder, ConversationManager
        print("âœ… Message management classes imported successfully")
        
        # Test message creation
        conv = ConversationManager()
        conv.add_user_message("Test thinking process output")
        conv.add_system_message("You are a cybersecurity expert")
        
        print(f"âœ… Conversation created with {conv.get_message_count()} messages")
        
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        return False
    
    # Test model availability 
    try:
        from Red.model import LLMModel
        import config
        
        print(f"âœ… Current sangria model: {config.llm_model_sangria}")
        print(f"âœ… Current config model: {config.llm_model_config}")
        
        # Show available models for switching
        print(f"\nğŸ“‹ Available models for easy switching:")
        print(f"   â€¢ {LLMModel.O3_MINI} (Advanced reasoning)")
        print(f"   â€¢ {LLMModel.GPT_4_1_MINI} (Fast and reliable)")
        print(f"   â€¢ {LLMModel.O4_MINI} (Cost optimized)")
        
    except Exception as e:
        print(f"âŒ Model configuration error: {e}")
        return False
    
    return True

def show_output_improvements():
    """Show what the enhanced output will look like."""
    print(f"\nğŸ¯ ENHANCED OUTPUT FEATURES")
    print("=" * 60)
    
    improvements = [
        "ğŸ’­ THINKING PROCESS: Shows the LLM's reasoning and thought process",
        "ğŸ”§ TOOL CALLS: Clear display of function calls and their arguments", 
        "ğŸ“ TOOL RESPONSES: Formatted output from executed commands",
        "ğŸ¯ MITRE METHODS: Identification of cybersecurity attack techniques",
        "ğŸ“Š ITERATION SUMMARIES: Concise progress updates for each step",
        "ğŸ ATTACK RESULTS: Clear success/failure indicators",
        "ğŸ’° TOKEN USAGE: Detailed cost tracking with formatted numbers",
        "ğŸ“‹ SESSION SUMMARY: Comprehensive overview of the entire attack",
        "ğŸ† FINAL OUTPUT: Professional conclusion with key insights"
    ]
    
    for improvement in improvements:
        print(f"   {improvement}")
    
    print(f"\nğŸ”„ MODEL SWITCHING:")
    print(f"   To switch from O3_MINI to GPT_4_1_MINI:")
    print(f"   1. Edit config.py")
    print(f"   2. Uncomment: # llm_model_sangria = LLMModel.GPT_4_1_MINI")
    print(f"   3. Comment out: llm_model_sangria = LLMModel.O3_MINI")
    print(f"   4. Same for llm_model_config if needed")

def simulate_attack_output():
    """Simulate what the attack output will look like."""
    print(f"\nğŸ¬ EXAMPLE OUTPUT PREVIEW")
    print("=" * 60)
    
    # Simulate session start
    print(f"\nğŸš€ STARTING ATTACK SESSION")
    print(f"{'='*80}")
    
    # Simulate iteration output
    print(f"\n{'='*60}")
    print(f"ğŸ¤– ITERATION 1 - LLM RESPONSE")
    print("="*60)
    
    print(f"\nğŸ’­ THINKING PROCESS:")
    print("-" * 30)
    print("I need to gather information about the target system first.")
    print("Let me start with basic reconnaissance commands to understand")
    print("the environment and identify potential attack vectors.")
    print("-" * 30)
    
    print(f"\nğŸ”§ TOOL CALL:")
    print(f"Function: run_command")
    print(f"Arguments: {{'command': 'whoami && pwd && ls -la'}}")
    
    print(f"\nğŸ“ TOOL RESPONSES:")
    print(f"  1. run_command: user@target:/home/user")
    
    print(f"\nğŸ¯ MITRE METHOD USED:")
    print(f"  T1082 - System Information Discovery")
    print("="*60)
    
    # Simulate session summary
    print(f"\n{'='*80}")
    print(f"ğŸ¯ ATTACK SESSION SUMMARY")
    print(f"{'='*80}")
    print(f"ğŸ“Š Session Statistics:")
    print(f"   Total iterations: 3")
    print(f"   Total conversation messages: 12")
    print(f"\nğŸ’° Token Usage:")
    print(f"   Prompt tokens: 1,250")
    print(f"   Completion tokens: 890")
    print(f"   Cached tokens: 450")
    print(f"   Total tokens used: 2,140")
    print(f"\nğŸ¯ Attack Outcome:")
    print(f"   Result: âœ… SUCCESS")
    print(f"{'='*80}")
    
    # Simulate final output
    print(f"\nğŸ† FINAL ATTACK RESULT")
    print(f"{'='*80}")
    print("âœ… ATTACK SUCCESSFUL!")
    print("The cybersecurity simulation achieved its objectives.")
    print(f"\nğŸ“‹ Key Insights:")
    print(f"   â€¢ Attack duration: 3 iterations")
    print(f"   â€¢ Computational cost: 2,140 tokens")
    print(f"   â€¢ Final command output: Successfully gained access to target system...")
    print(f"{'='*80}")

if __name__ == "__main__":
    print("ENHANCED SANGRIA OUTPUT TESTING")
    print("=" * 50)
    
    # Test core functionality
    if test_enhanced_output_format():
        print("âœ… All core functionality working!")
        
        # Show improvements
        show_output_improvements()
        
        # Show example output
        simulate_attack_output()
        
        print(f"\nğŸ‰ SETUP COMPLETE!")
        print("Your sangria.py now has enhanced console output with:")
        print("â€¢ Detailed thinking process display")
        print("â€¢ Professional formatting and progress tracking") 
        print("â€¢ Easy model switching between O3_MINI and GPT_4_1_MINI")
        print("â€¢ Comprehensive session summaries")
        print("\nRun 'python3 main.py' to see the enhanced output in action!")
        
    else:
        print("âŒ Some functionality needs attention")
        print("Please check the import paths and dependencies")
